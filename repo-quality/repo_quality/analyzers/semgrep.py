import json
import subprocess
import tempfile
from pathlib import Path
from typing import Dict, Any


def analyze_semgrep(repo_path: Path) -> Dict[str, Any]:
    """Analyze code for security vulnerabilities using Semgrep and custom static checks.

    Args:
        repo_path: Path to the repository.

    Returns:
        Dictionary with security metrics.
    """
    # Custom static checks for secrets, risky patterns, and best practices
    custom_findings = []
    # Scan all files for secrets and risky patterns
    for ext in ["*.js", "*.jsx", "*.ts", "*.tsx", "*.py"]:
        for file in repo_path.rglob(ext):
            # Skip node_modules, venv, etc.
            if any(exc in file.parts for exc in {'node_modules', 'venv', '__pycache__', 'dist', 'build', '.git', 'coverage', '.next'}):
                continue
            try:
                with open(file, 'r', encoding='utf-8', errors='ignore') as f:
                    for i, line in enumerate(f, 1):
                        line_lower = line.lower()
                        
                        # Secret patterns - more comprehensive
                        if any(k in line_lower for k in ['password', 'secret', 'api_key', 'apikey', 'private_key', 'access_token', 'auth_token']):
                            custom_findings.append({
                                'type': 'Potential Secret',
                                'file': str(file.relative_to(repo_path)),
                                'line': i,
                                'content': line.strip()[:100]  # Limit snippet length
                            })
                        
                        # Hardcoded credentials
                        if any(k in line_lower for k in ['password', 'secret', 'api_key', 'token', 'apikey']):
                            if any(p in line for p in ['="', "='", ': "', ": '"]):
                                custom_findings.append({
                                    'type': 'Hardcoded Credential',
                                    'file': str(file.relative_to(repo_path)),
                                    'line': i,
                                    'content': line.strip()[:100]
                                })
                        
                        # Dangerous functions
                        if any(d in line for d in ['eval(', 'exec(', 'child_process', 'shell=True', 'pickle.loads', 'yaml.load(']):
                            custom_findings.append({
                                'type': 'Dangerous Function',
                                'file': str(file.relative_to(repo_path)),
                                'line': i,
                                'content': line.strip()[:100]
                            })
                        
                        # SQL Injection risks
                        if any(s in line_lower for s in ['execute("', 'execute(\'', 'cursor.execute(f"', '.raw(']):
                            custom_findings.append({
                                'type': 'SQL Injection Risk',
                                'file': str(file.relative_to(repo_path)),
                                'line': i,
                                'content': line.strip()[:100]
                            })
                        
                        # Insecure dependencies (Python)
                        if file.suffix == '.py' and 'import' in line:
                            if any(m in line for m in ['pickle', 'eval', 'exec']):
                                custom_findings.append({
                                    'type': 'Insecure Import',
                                    'file': str(file.relative_to(repo_path)),
                                    'line': i,
                                    'content': line.strip()[:100]
                                })
                        
                        # TODO/FIXME/HACK comments (code quality)
                        if any(tag in line for tag in ['TODO:', 'FIXME:', 'HACK:', 'XXX:', 'BUG:']):
                            custom_findings.append({
                                'type': 'Code Quality Issue',
                                'file': str(file.relative_to(repo_path)),
                                'line': i,
                                'content': line.strip()[:100]
                            })
                        
                        # AI-generated code markers and placeholders
                        ai_markers = [
                            'generated by copilot', 'generated by ai', 'chatgpt', 'generated code',
                            'placeholder', 'implement this', 'add your code here', 'your code here',
                            'not implemented', 'unimplemented', 'stub function', 'dummy implementation',
                            'lorem ipsum', 'example code', 'sample code'
                        ]
                        if any(marker in line_lower for marker in ai_markers):
                            custom_findings.append({
                                'type': 'AI/Placeholder Code',
                                'file': str(file.relative_to(repo_path)),
                                'line': i,
                                'content': line.strip()[:100]
                            })
                        
                        # Empty functions/methods (potential placeholders)
                        if file.suffix == '.py':
                            if 'def ' in line and line.strip().endswith(':'):
                                # Check if next line is just 'pass'
                                custom_findings.append({
                                    'type': 'Potential Placeholder Function',
                                    'file': str(file.relative_to(repo_path)),
                                    'line': i,
                                    'content': line.strip()[:100]
                                })
                        
                        # Missing best practices (JS/TS): no use strict (only on line 1)
                        if (file.suffix in ['.js', '.ts']) and i == 1 and 'use strict' not in line and "'use strict'" not in line:
                            custom_findings.append({
                                'type': 'Missing Best Practice',
                                'file': str(file.relative_to(repo_path)),
                                'line': i,
                                'content': 'Missing "use strict" at top of file'
                            })
            except Exception:
                continue
    try:
        with tempfile.NamedTemporaryFile(mode='w+', suffix='.json', delete=False) as tmp_file:
            tmp_json = tmp_file.name

        result = subprocess.run(
            ['semgrep', '--config=auto', '--json', '--output', tmp_json, str(repo_path)],
            capture_output=True,
            text=True,
            timeout=600
        )
        if result.returncode not in (0, 1):  # 1 is ok for semgrep if findings
            raise Exception(f"Semgrep failed: {result.stderr}")

        with open(tmp_json, 'r') as f:
            data = json.load(f)

        # Count by severity and collect all findings
        severity_counts = {'CRITICAL': 0, 'HIGH': 0, 'MEDIUM': 0, 'LOW': 0, 'INFO': 0}
        findings = []
        for result_item in data.get('results', []):
            severity = result_item.get('extra', {}).get('severity', 'INFO').upper()
            if severity in severity_counts:
                severity_counts[severity] += 1
            finding = {
                'severity': severity,
                'message': result_item.get('extra', {}).get('message', ''),
                'path': result_item.get('path', ''),
                'start': result_item.get('start', {}),
                'end': result_item.get('end', {}),
                'rule_id': result_item.get('check_id', '')
            }
            findings.append(finding)

        # Clean up
        Path(tmp_json).unlink(missing_ok=True)

        return {
            'security_critical': severity_counts['CRITICAL'],
            'security_high': severity_counts['HIGH'],
            'security_medium': severity_counts['MEDIUM'],
            'security_low': severity_counts['LOW'],
            'security_info': severity_counts['INFO'],
            'semgrep_findings': findings,
            'custom_static_findings': custom_findings
        }
    except (subprocess.TimeoutExpired, json.JSONDecodeError, FileNotFoundError) as e:
        raise Exception(f"Failed to analyze with Semgrep: {e}")